{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ProCtrlDataLoaderV2 as DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(lineno)s - %(levelname)s - %(message)s')\n",
    "logger.setLevel(logging.WARNING)\n",
    "fhandler = logging.FileHandler(filename='logging.log', mode='w')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bio'\n",
      "'arb'\n",
      "'control'\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(DataLoader)\n",
    "start_path = './Jun14_data/' # Put path to head of raw data file tree here\n",
    "\n",
    "loadTest = DataLoader.ProCtrlDataLoader(start_path, ['bio','arb','control'],[], ['sess2','sess5', 'sess6']) # Can be used to delineate which subsets of data are to be considered in current calculations (which [Groups],[Subjects],[Sessions])\n",
    "\n",
    "loadTest.loaddata() # Build an object which holds all of the data for each participant within selected tags\n",
    "loadTest.printDict() # Confirms correct subjects have been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs: Single group, subject, and session of interest\n",
    "# Output: two csv (one for pre, one for post) containing classification, goal, and acc at each timepoint for each gesture\n",
    "# Requires that a loadTest object has been initialized and loaded (done in prior block)\n",
    "def prep_cm_dfs(group,subject,sess): \n",
    "    session = loadTest.data_dict[group][subject][sess] # Load data for selected session (dict containing pre+post individually)\n",
    "    \n",
    "    for pre_post in session.keys():\n",
    "        hold = pd.DataFrame(index = range(400)) # dummy df to hold all the trials (max 400 tp in a single trial)\n",
    "\n",
    "        if 'trained' in pre_post: # Only build csvs for pre/post, ignore bio/arb sections\n",
    "            logging.info(pre_post)\n",
    "            df = session[pre_post] # create df to hold raw data\n",
    "\n",
    "            pre_post_string = 'pre' \n",
    "            if 'post' in pre_post:\n",
    "                pre_post_string = 'post'\n",
    "\n",
    "            logging.info(pre_post_string)\n",
    "\n",
    "            for mc in df.chunk_bounds: # chunks are defined by trials (each gesture), iterate through all trials in session\n",
    "                j = 0\n",
    "                for bounds in df.chunk_bounds[mc]:\n",
    "                    j += 1\n",
    "                    start = bounds[0]\n",
    "                    end = bounds[1]\n",
    "\n",
    "                    chunk_goal = df.armgame_df.loc[start:end, 'goal'] # Get goal data\n",
    "\n",
    "                    chunk_class = df.armgame_df.loc[start:end, 'class'] # Get classification data\n",
    "\n",
    "                    chunk_acc = np.where(chunk_goal == chunk_class, 1, 0) # calculate acc at each tp\n",
    "\n",
    "                    npArray = np.array(chunk_acc)\n",
    "                    val = np.argmax(npArray > 0) # find the first non-zero accuracy value (first correct classification)\n",
    "\n",
    "                    # Drop values prior to first correct classification\n",
    "                    chunk_goal = pd.Series(chunk_goal[val:-1])\n",
    "                    chunk_class = pd.Series(chunk_class[val:-1])\n",
    "                    chunk_acc = pd.Series(chunk_acc[val:-1])\n",
    "\n",
    "                    chunk_goal = chunk_goal.reset_index(drop=True)\n",
    "                    chunk_class = chunk_class.reset_index(drop=True)\n",
    "                    chunk_acc = chunk_acc.reset_index(drop=True)\n",
    "\n",
    "\n",
    "                    # Resize hold if it isn't large enough to contain new data\n",
    "                    if len(chunk_class.index) > len(hold.index):\n",
    "                        new_df = pd.DataFrame(index = range(len(chunk_class.index)))\n",
    "                        hold = new_df.join(hold)\n",
    "                        \n",
    "\n",
    "                    # add columns for current trial to session df\n",
    "                    col_string = mc + '_' + str(j) + '_' + pre_post + '_'\n",
    "                    hold[col_string + 'class'] = chunk_class\n",
    "                    hold[col_string + 'goal'] = chunk_goal\n",
    "                    hold[col_string + 'acc'] = chunk_acc\n",
    "\n",
    "            # Save it homie\n",
    "            file_name = 'ind_sub_acc_prep/' + subject +'_' + sess + '_' + pre_post_string + '_cm_prep.csv'\n",
    "            hold.to_csv(file_name)\n",
    "\n",
    "# Loop through all groups, subjects, and sessions in loadTest to build cm dfs\n",
    "for group in loadTest.data_dict:\n",
    "    for subj in loadTest.data_dict[group]:\n",
    "        for sess in loadTest.data_dict[group][subj]:\n",
    "            prep_cm_dfs(group, subj, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "from hashlib import new\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "acc_prep_files = glob.glob('./ind_sub_acc_prep/*.csv') # Load in previously prepped cm files\n",
    "\n",
    "time_windows = [(0,49),(50,99),(100,149),(150,199)] # Set time windows of interest\n",
    "\n",
    "gestures = ['rest','open','close'] # Set gestures of interest\n",
    "\n",
    "new_cols = ['subj', 'group', 'sess', 'pre_post'] # Set tag column names \n",
    "\n",
    "# Populate other columns of interest (for each tp window + gesture combo)\n",
    "for gesture in gestures:\n",
    "    for window in time_windows:\n",
    "        string = gesture + '_' + str(window[0]) + '-' + str(window[1]) + 'tp'\n",
    "        new_cols.append(string)\n",
    "\n",
    "logging.info(new_cols)\n",
    "\n",
    "agg_windowed_class_acc = pd.DataFrame(columns=new_cols) # make df with these columns\n",
    "\n",
    "for file in acc_prep_files:\n",
    "    file_name = file.split('/')[-1]\n",
    "    file_name = file_name.split('_')\n",
    "\n",
    "    logging.info(file_name)\n",
    "    subj = file_name[0].split('-')[-1]\n",
    "    \n",
    "    group = 'bio'\n",
    "    if 'ar' in subj:\n",
    "        group = 'arb'\n",
    "    if 'co' in subj:\n",
    "        group = 'control'\n",
    "    sess = file_name[1]\n",
    "    pre_post = file_name[2]\n",
    "\n",
    "    logging.info(subj,sess,pre_post)\n",
    "\n",
    "    curr_file = pd.read_csv(file)\n",
    "\n",
    "    acc_cols = [x for x in curr_file.columns if 'acc' in x]\n",
    "\n",
    "    rest_cols = [x for x in acc_cols if 'rest' in x]\n",
    "    open_cols = [x for x in acc_cols if 'open' in x]\n",
    "    close_cols = [x for x in acc_cols if 'close' in x]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    row = pd.DataFrame(columns=new_cols)\n",
    "    row.loc[0,'subj'] = subj \n",
    "    row.loc[0,'group'] = group\n",
    "    row.loc[0,'sess'] = sess\n",
    "    row.loc[0,'pre_post'] = pre_post\n",
    "\n",
    "\n",
    "    for window in time_windows:\n",
    "        start = window[0]\n",
    "        stop = window[1]\n",
    "        for grouping in [(rest_cols,'rest'),(open_cols,'open'),(close_cols,'close')]:\n",
    "            cols = grouping[0]\n",
    "            gesture = grouping[1]\n",
    "\n",
    "            temp_avg = -1\n",
    "\n",
    "            for column in cols:\n",
    "                chunk_avg = curr_file.loc[start:stop, column].mean()\n",
    "\n",
    "                if not chunk_avg:\n",
    "                    logging.info(subj + sess + 'no chunk?' + column)\n",
    "\n",
    "                if temp_avg == -1:\n",
    "                    temp_avg = chunk_avg\n",
    "                else:\n",
    "                    temp_avg = (temp_avg + chunk_avg) / 2\n",
    "\n",
    "            col = gesture + '_' + str(window[0]) + '-' + str(window[1]) + 'tp'\n",
    "            if temp_avg >= 0:\n",
    "                row[col] = temp_avg\n",
    "            # print(row)\n",
    "    agg_windowed_class_acc = pd.concat([agg_windowed_class_acc, row], axis=0)\n",
    "\n",
    "    agg_windowed_class_acc = agg_windowed_class_acc.sort_values(by=['group','subj','sess'])\n",
    "\n",
    "    outpath = 'LearningMeasureHunter/'\n",
    "\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "\n",
    "    agg_windowed_class_acc.to_csv(outpath + 'class_avg_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = path + '/LearningMeasureHunter/'\n",
    "\n",
    "prepped_lm_files = glob.glob(path + 'class_avg_prep.csv')\n",
    "\n",
    "output_df = pd.DataFrame(columns=['group','sess','subj','pre_post','gesture','time_window','class_acc'])\n",
    "\n",
    "test = pd.MultiIndex.from_frame(output_df)\n",
    "\n",
    "prepped_file = pd.read_csv(prepped_lm_files[0])\n",
    "\n",
    "win_codes = []\n",
    "for window in time_windows:\n",
    "    win_codes = [*win_codes, str(window[0]) + '-' + str(window[1]) + 'tp']\n",
    "\n",
    "logging.info(prepped_file['subj'].unique())\n",
    "logging.info(win_codes)\n",
    "\n",
    "arrays = [\n",
    "    prepped_file['subj'].unique(),\n",
    "    ['sess2','sess5','sess6'],\n",
    "    ['pre','post'],\n",
    "    ['rest','open','close'],\n",
    "    win_codes\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_product(arrays, names=['subj','sess','pre_post','gesture','time_window'])\n",
    "\n",
    "df = pd.DataFrame(index=index,columns=['group','class_acc'])\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "for i in range(len(prepped_file)):\n",
    "    subj = prepped_file.loc[i,'subj']\n",
    "    sess = prepped_file.loc[i,'sess']\n",
    "    pre_post = prepped_file.loc[i,'pre_post']\n",
    "\n",
    "    for gesture in gestures:\n",
    "        for window in win_codes:\n",
    "            cols = [x for x in prepped_file.columns if gesture in x and window in x]\n",
    "            for column in cols:\n",
    "\n",
    "                val = prepped_file.loc[i,column]\n",
    "\n",
    "                df.loc[idx[subj,sess,pre_post,gesture,window], 'class_acc'] = val\n",
    "\n",
    "                group = 'bio'\n",
    "                if 'ar' in subj:\n",
    "                    group = 'arb' \n",
    "                if 'co' in subj:\n",
    "                    group = 'control'\n",
    "\n",
    "                df.loc[idx[subj,sess,pre_post,gesture,window], 'group'] = group\n",
    "df = df.sort_values(['subj','sess','pre_post','gesture','time_window'])\n",
    "df.to_csv(outpath + 'raw_classacc_avgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_save = glob.glob(outpath + 'raw*avgs*')\n",
    "\n",
    "for file in re_save:\n",
    "    temp = pd.read_csv(file)\n",
    "\n",
    "    temp = temp[temp['class_acc'].notna()]\n",
    "\n",
    "    temp.to_csv(outpath + 'tagged_classacc_avgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db72871f2429c0659128210f5bc2689eafb859f570228ddc214587626bbe63a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
